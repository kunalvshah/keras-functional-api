{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A beginner's guide to Keras Functional API\n",
    "\n",
    "I am sure a lot of you agree that Tensorflow Keras is rich with Sequential model API. Sequential models are great but recently I have been playing with the Keras Functional APIs and found that it is even better.  \n",
    "\n",
    "***The Keras Functional API*** is a way to create models that are more flexible than the Sequential API. The Functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. But what if your model has multiple inputs? And it is also possible that you might need to design different models for diverse types of inputs. It turns out that sequence models are not a smart choice in such cases.\n",
    "\n",
    "For example, a Wine Reviews dataset from Kaggle. The original problem posted on kaggle.com was to build a model to identify the variety of wine from the parameters like description, price, region, and country of origin.\n",
    "\n",
    "You can download the wine review dataset from here.\n",
    "\n",
    "As you can see from this dataset, we have multiple inputs for this data. Also, the relationship between the input and output is not always clear. For example, the relationship between the parameters *country of origin* and the *variety* of wine is quite simple but the relationship between the parameters *description* and the *variety* of wine is not that simple. \n",
    "\n",
    "You may need to build a separate model to use the relationship between parameters *description* and *variety* of wine and a separate model for the relationship between parameters *country of origin* and *variety* of wine.\n",
    "\n",
    "But what if you could write a model that combines both models? The Keras Functional API helps us achieve that goal.\n",
    "If we want to work with the above problem, it seems that best results can be obtain by using ***Wide and Deep Networks***. There are tons of resources available on this subject and the best one is [here](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html).\n",
    "\n",
    "## Wide and Deep Learning Networks\n",
    "\n",
    "If you have read the [link](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html) I posted above, you now know how *Wide and Deep Learning* works. But why it is the better choice for this solution?\n",
    "\n",
    "It turns out that it's useful for generic large-scale regression and classification problems with sparse inputs (categorical features with a large number of possible feature values). Don't worry if you don't understand this long sentence in one go. We will see this in action with the code. What I am trying to say is that in a classification problem, when we have a large number of possible classes - in this case, varieties of wine (there are 619 varieties of wine in our dataset) and we are doing large-scale regression (you will see in a while why it is the case), *Wide & Deep Learning* is the weapon of choice.\n",
    "\n",
    "## Keras Functional API comes to rescue\n",
    "\n",
    "Now that we agree that the best way to approach this problem is by using two models with two different types of inputs. But the Keras Sequential models cannot give you that flexibility. That's where Keras Functional API comes to the rescue.\n",
    "\n",
    "Let's see that in action. Let's rephrase our problem statement to simplify.\n",
    "\n",
    "**Let's say we want to predict the price of the wine based on the features - *description* and the *variety*.**\n",
    "\n",
    "So our inputs are \n",
    " - **Description:**   \n",
    " This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
    " - **Variety:**   \n",
    " Cabernet Sauvignon\n",
    " \n",
    "and our predction should be \n",
    " - **Price:**   \n",
    "  235.0\n",
    "     \n",
    "\n",
    "I am going to walk you through the code. You can find complete code on my github repository. I will be posting the link in the comment section.\n",
    "\n",
    "First, let's start by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessory libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "layers = keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain data and preprocess the inputs\n",
    "\n",
    "I have already downloaded the dataset from [here](https://www.kaggle.com/zynicide/wine-reviews?select=winemag-data_first150k.csv) and stored in my local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930, 11)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./datasets/winemag-data_first150k.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have close to 150k records and 11 columns. Hence, there  are 11 features. We may not be interested in all features. Let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in only a few features here. We want a description, variety, and price. As this is a supervised learning algorithm, we will use price as the output label for our training and test dataset.\n",
    "\n",
    "I also noticed we have some null values. Also if you look at the Kaggle dataset description, you will find there are some invalid values in the data. We can remove the records that have null values.\n",
    "\n",
    "### Data Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137235, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[pd.notnull(data['price'])] #obviously, we want only records that have price mentioned.\n",
    "data = data[pd.notnull(data['variety'])]\n",
    "\n",
    "# we don't need to find null values for description column. There is no record that does not have description. I can see that on kaggle dataset page.\n",
    "#let's print the shape of the data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we removed quite a few records from our dataset. We removed close to 14k rows that are inconsistent with the inputs we need.\n",
    "\n",
    "\n",
    "### Split the data in train and test sets ###\n",
    "\n",
    "Let's split the data in the train and the test set. I usually go for 75:25 for train:test split. You can modify this hyperparameter. Try to put different values of train:test split and see  if it improves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels\n",
      "description_train (109788,)\n",
      "variety_train (109788,)\n",
      "labels_train (109788,)\n",
      "Train features and labels (27447,)\n",
      "description_test (27447,)\n",
      "variety_test (27447,)\n",
      "labels_test (27447,)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .8)\n",
    "\n",
    "#It's always a good idea to shuffle the data before the split. You can also improvise this code by using best practices for the split\n",
    "\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Train features and labels\n",
    "description_train = data['description'][:train_size]\n",
    "variety_train = data['variety'][:train_size]\n",
    "labels_train = data['price'][:train_size]\n",
    "\n",
    "# Test features and labels\n",
    "description_test = data['description'][train_size:]\n",
    "variety_test = data['variety'][train_size:]\n",
    "labels_test = data['price'][train_size:]\n",
    "\n",
    "print(\"Train features and labels\")\n",
    "print(\"description_train\", description_train.shape)\n",
    "print(\"variety_train\", variety_train.shape)\n",
    "print(\"labels_train\", labels_train.shape)\n",
    "\n",
    "print(\"Train features and labels\", description_test.shape)\n",
    "print(\"description_test\", description_test.shape)\n",
    "print(\"variety_test\", variety_test.shape)\n",
    "print(\"labels_test\", description_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "***Great*** , we now have 109788 records for training and 27447 records for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing input features for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description:\n",
      " This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
      "\n",
      "variety:\n",
      " Cabernet Sauvignon\n",
      "\n",
      "price:\n",
      " 235.0\n"
     ]
    }
   ],
   "source": [
    "#Let's check sample of our first feature - description\n",
    "\n",
    "print(\"description:\\n\", description_train[0])\n",
    "print(\"\\nvariety:\\n\", variety_train[0])\n",
    "print(\"\\nprice:\\n\", labels_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1: Variety\n",
    "\n",
    "As you can see, the variety is not a complicated feature. It's just a class. One of the best practices is to use a Keras utility to convert each of these varieties to integer representation and then one-hot vectors for each input to indicate the variety. Remember our earlier discussion on why *Wide & Deep network* is useful?  Our vector to represent one-hot encoding for a variety for each record is close to 619 elements long. Also, it is sparse. \n",
    "\n",
    "619 elements long because there are close to 619 classes in varieties in our dataset. Also, the data is *sparse* because for each record, except one element corresponding to that variety, the rest of the elements are 0s. And as you might have read from the link on *Wide & Deep Networks*,  it is useful for classification problems with sparse inputs. So this is the best choice we have so far.\n",
    "\n",
    "So let's go ahead and prepare one-hot-vector for the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(variety_train)\n",
    "encoder.fit(data['variety'])\n",
    "variety_train_enc = encoder.transform(variety_train)\n",
    "variety_test_enc = encoder.transform(variety_test)\n",
    "num_classes = np.max(variety_train_enc) + 1\n",
    "\n",
    "# Convert labels to one hot vectors\n",
    "variety_train_onehot = keras.utils.to_categorical(variety_train_enc, num_classes)\n",
    "variety_test_onehot = keras.utils.to_categorical(variety_test_enc, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2: Wine description\n",
    "\n",
    "For complicated features like the *description* - which is a collection of text, the best model to use is Bag-Of-Words model - more information on that [here](https://en.wikipedia.org/wiki/Bag-of-words_model).\n",
    "\n",
    "A quick recap: a *bag of words* model looks for the presence of words in each input to our model. You can think of each input as a bag of Scrabble tiles, where each tile contains a word instead of a letter. The model doesn’t take into account the order of words in a description, just the presence or absence of a word.\n",
    "\n",
    "We will start by preparing a vocabulary or bag of words from our dataset. We will limit the size of the vocabulary to 15,000 words. This parameter is ***tunable***. I chose 15000 words because I think the description for a single item (wine) will use more or less the same set of words within the 15000 different words. so I am assuming a dictionary or *Bag of Words* 15000 words should be sufficiently long. We will take all descriptions from all records, split them into words, and store them into our *Bag of Words*. Keras has pretty cool libraries to do this easily.\n",
    "\n",
    "We can take this representation of feature *description* in our (Wide Model* because this input to our model for each description will be a 15k element wide vector with 1s and 0s indicating the presence of words from our vocabulary in a particular description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 15000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=voc_size, char_level=False)\n",
    "tokenizer.fit_on_texts(description_train)\n",
    "\n",
    "#convert each description to a bag of words vector\n",
    "\n",
    "desc_bow_train = tokenizer.texts_to_matrix(description_train)\n",
    "desc_bow_test = tokenizer.texts_to_matrix(description_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Let's check the sample\n",
    "\n",
    "print(description_train[0])\n",
    "print(desc_bow_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the first record has a description in words, and `desc_bow_train` has it converted into vectors of 0s and 1s. The vector has element 1 where that word is part of the *Bag of Words* and 0 where that word is not part of *Bag of Words*. \n",
    "\n",
    "As you can see, once you convert words into 0s and 1s, the sentence loses all grammatical context. **We may not be able to get good results if we use this only with Wide Model**. That's why we need Deep Model as well. As I said above, \"Description\" is a complex feature. So while I am using the simpler version of it with *Wide Network*, I want to use *Deep Network* to figure out the complex relationship between the *Description* and *Output*, without losing the context. \n",
    "\n",
    "The best way to use the feature *Description* for Deep Network is to use ***Word Embedding***. You can learn more about word embedding [here](https://en.wikipedia.org/wiki/Word_embedding) but the short version is that they provide a way to map a word to vectors so that similar words are closer together in vector space.\n",
    "\n",
    "We will start by converting each description to a vector of integers corresponding to each word in our bag of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embed = tokenizer.texts_to_sequences(description_train)\n",
    "test_embed = tokenizer.texts_to_sequences(description_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this has done. Let's print the first description in words and it's sequence form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
      "\n",
      " [19, 4, 882, 13, 452, 1, 120, 302, 2, 47, 2, 104, 24, 7, 159, 324, 1159, 14, 1240, 155, 27, 20, 545, 27, 80, 360, 1, 163, 405, 501, 1932, 23]\n"
     ]
    }
   ],
   "source": [
    "print(description_train[0])\n",
    "print(\"\\n\",train_embed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, `texts_to_sequences` replaced the words with the corresponding index of that word in our *Bag of Words*.\n",
    "\n",
    "One issue that we have with this transformation is that all descriptions are of different length. We need to make sure the embedding vector is of the same length. We will pad the shorter vectors with 0s. Let's say the maximum length of the *description* we want to allow is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(train_embed, maxlen=seq_length)\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(test_embed, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models using Functional API ##\n",
    "\n",
    "Now that we have completed preparing for the features, it is time to build models using Functional API. As discussed earlier, the benefit of using Functional API is that we can prepare multiple models for multiple inputs and combine both models. \n",
    "Here the *Description* and *Variety* are two separate inputs, but we will still be able to prepare the *Wide Model* and pass these inputs to the model.\n",
    "\n",
    "### Model 1: Wide Model\n",
    "\n",
    "We will define two input layers, one for *decription* and one for *variety* and merge them.\n",
    "\n",
    "The first input to our *Wide Model* is the tokenized version of the feature *description*. Recall that it is the vector, each of the length of 15,000, with each element as 0 or 1.\n",
    "\n",
    "The second input is *variety* - which is a one-hot vector of size `num_classes` as defined above, which in our case is 619\n",
    "\n",
    "We will define these two layers and then merge them into a dense output layer to predict the price of the wine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 619)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15619)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          3998720     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,998,977\n",
      "Trainable params: 3,998,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "desc_inputs = layers.Input(shape=(voc_size,))\n",
    "var_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([desc_inputs, var_inputs])\n",
    "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merged_layer)\n",
    "wide_model = keras.Model(inputs=[desc_inputs, var_inputs], outputs=predictions)\n",
    "\n",
    "# compile the model\n",
    "\n",
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "wide_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some explanation of the summary of Wide Model**\n",
    "\n",
    "As we discussed, \n",
    "The first input is vectors of the length of 15,000 elements with 0s and 1s. That is the description feature. Here it is the first line with `InputLayer` with `shape (none, 15000)`\n",
    "\n",
    "The second input is a one-hot vector of *varieties*. There are 619 varieties. So to describe a variety, we use one hot vector of length 619, with 618 elements 0 and one element as 1 at the index of that variety of the wine. \n",
    "\n",
    "We are not training the model yet. We want to build another *Deep Network model*, merge it with this *Wide Model* and then train that hybrid model\n",
    "\n",
    "So with this model ready, let's build the *Deep Network Model*\n",
    "\n",
    "### Model 2: Deep Model\n",
    "\n",
    "Just like we did with Wide Model, here too we need to create a layer and add it to our model. \n",
    "\n",
    "As we are using **word embedding** for *Deep Network*, we should be using an **embedding layer**. There are many pre-train embedding layers you can use. For that, you need to download the layers and load them here.\n",
    "\n",
    "The second option is to learn the embedding layer. I am using the second option because this is a non-production problem and we can easily train our network to learn from our *Bag of Words*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 8)            120000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 121,601\n",
      "Trainable params: 121,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first we define our input layer\n",
    "deep_inputs = layers.Input(shape=(seq_length,))\n",
    "\n",
    "# we feed this inputs to embedding layer, this is where it will learn the embeddings\n",
    "# The output of the Embedding layer will be a 3D vector with shape: [batch size, sequence length of 200), embedding dimension (8 in this case)]\n",
    "embedding = layers.Embedding(voc_size, 8,   input_length=seq_length)(deep_inputs)\n",
    "\n",
    "#Now we need to flatten it\n",
    "embedding = layers.Flatten()(embedding)\n",
    "\n",
    "#Let's build the model with these layers\n",
    "\n",
    "_out = layers.Dense(1, activation='linear')(embedding)\n",
    "\n",
    "deep_model = keras.Model(inputs=deep_inputs, outputs=_out)\n",
    "deep_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some explaination of the summary of Deep Model.**\n",
    "\n",
    "The first input is vectors of the length of 200 elements with the location of words in the vocabulary. That is the description feature. Here it is the first line with `InputLayer` with `shape (none, 200)`\n",
    "\n",
    "The second input is the output from the embedded layer. As mentioned above, a 3D vector with `shape: batch = none, the sequence length of 200, and the embedding dimension of 8` in this case\n",
    "\n",
    "in the flatten layer, we are taking `200 x 8` and flatting it, giving us a shape of `200x8=1600`\n",
    "\n",
    "## Putting Wide and Deep Networks togather\n",
    "\n",
    "Now it is time for us to put both networks together and train them for our data.\n",
    "\n",
    "We will do this by creating a layer that concatenates the outputs from each model. Then, we merge them into a fully connected dense layer. And finally, define a combined model that combines the input and output from each one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 15000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 619)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15619)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 8)       120000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          3998720     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1600)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1601        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,120,581\n",
      "Trainable params: 4,120,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combined_model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment of truth\n",
    "\n",
    "It’s time to run training and evaluation. It will tell us how our model is doing with previously unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 466.5967 - mae: 10.9279\n",
      "Epoch 2/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 404.0397 - mae: 9.2653\n",
      "Epoch 3/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 276.4466 - mae: 8.3059\n",
      "Epoch 4/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 219.0885 - mae: 7.3757\n",
      "Epoch 5/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 161.8008 - mae: 6.4731\n",
      "Epoch 6/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 117.5619 - mae: 5.6687\n",
      "Epoch 7/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 106.2482 - mae: 5.0818\n",
      "Epoch 8/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 95.8084 - mae: 4.5677\n",
      "Epoch 9/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 64.8215 - mae: 4.0852\n",
      "Epoch 10/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 45.6391 - mae: 3.7310\n",
      "Epoch 11/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 37.8446 - mae: 3.4917\n",
      "Epoch 12/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 33.6189 - mae: 3.2691\n",
      "Epoch 13/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 28.2737 - mae: 2.9963\n",
      "Epoch 14/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 29.6449 - mae: 2.9507\n",
      "Epoch 15/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 22.6972 - mae: 2.6919\n",
      "Epoch 16/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 23.0144 - mae: 2.6636\n",
      "Epoch 17/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 20.9692 - mae: 2.5347\n",
      "Epoch 18/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 20.0594 - mae: 2.4869\n",
      "Epoch 19/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 18.3877 - mae: 2.3773\n",
      "Epoch 20/20\n",
      "858/858 [==============================] - 10s 12ms/step - loss: 17.2195 - mae: 2.2944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f51afb83100>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training - this might take a while\n",
    "combined_model.fit([desc_bow_train, variety_train_onehot] + [train_embed], labels_train, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with each epoch loss - MSE is going down, which is always a good sign that we are doing something right.\n",
    "\n",
    "Next, let's evaluate our model on previously unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 4ms/step - loss: 883.3397 - mae: 9.2292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[883.3397216796875, 9.229154586791992]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate([desc_bow_test, variety_test_onehot] + [test_embed], labels_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test MSE is much higher than our train MSE. Which is not a good sign but I am going to leave it up to the audience to optimize the code.\n",
    "\n",
    "Now let's run the prediction on all our test datasets and see what we got. \n",
    "\n",
    "Finally, we trained our model to take description and variety and predict the price. Let's see how it is doing. By code below, we are giving our entire test data set that it has not seen before and we will see what it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combined_model.predict([desc_bow_test, variety_test_onehot] + [test_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This bold, spicy wine will appeal to those who love modern reds with thick concentration and lingering oak-driven flavors. Black cherry, prune and ripe blueberry do come into view, but the protagonist here is the oak. The wine has chewy tannins, good length on the finish and would pair with grilled meats or aged cheeses.\n",
      "Predicted:  50.215633 Actual:  49.0\n",
      "Difference:  1.2156333923339844 \n",
      "\n",
      "Average prediction difference:  0.24312667846679686\n",
      "A musky perfume note is sultry and exotic in this rich, textured Pinot Grigio, which was fermented on its skins and matured in oak. The fruity palate offers penetrating dried-pear, nut oil and apple flavors, which are layered with citrusy acids and soft, tea-leaf-like tannins that linger on the finish.\n",
      "Predicted:  33.513668 Actual:  24.0\n",
      "Difference:  9.513668060302734 \n",
      "\n",
      "Average prediction difference:  2.145860290527344\n",
      "Fresh and healthy for Toro Malvasia, with soft apple and sweet lime flavors. The feel and approach are good, and the wine is acidic but not too much, which helps preserve the mouthfeel. Finishes nice and standard.\n",
      "Predicted:  18.809105 Actual:  11.0\n",
      "Difference:  7.809104919433594 \n",
      "\n",
      "Average prediction difference:  3.7076812744140626\n",
      "Soft, young and fruity, with juicy black berry fruit flavors and only light tannins. Think barbecue.\n",
      "Predicted:  12.314702 Actual:  12.0\n",
      "Difference:  0.31470203399658203 \n",
      "\n",
      "Average prediction difference:  3.770621681213379\n",
      "This is an extraordinarily rich Zinfandel. It explodes in jammy blackberries, blueberries and cherries, with cola, mocha, currant, smoked meat and black pepper complexities. Could be a bit firmer in acidity, with greater structure, but it's nice and dry. Drink now for fruity exuberance.\n",
      "Predicted:  39.0284 Actual:  34.0\n",
      "Difference:  5.028400421142578 \n",
      "\n",
      "Average prediction difference:  4.776301765441895\n"
     ]
    }
   ],
   "source": [
    "num_predictions = 5\n",
    "diff = 0\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    val = predictions[i]\n",
    "    print(description_test.iloc[i])\n",
    "    print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i])\n",
    "    diff += abs(val[0] - labels_test.iloc[i])\n",
    "    print('Difference: ',abs(val[0] - labels_test.iloc[i]), '\\n')\n",
    "    print('Average prediction difference: ', diff / num_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "      \n",
    "         \n",
    "As you can, see our model is decently accurate. Barring a few examples, it's price prediction is very close. \n",
    "\n",
    "For the first example, Based on the variety and description, we predicted that the price of wine should 50 and the actual price is 49. \n",
    "\n",
    "The average prediction difference for 5 example is appx. $4 which is not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What’s next?\n",
    "\n",
    "I want to improvise this model by putting some optimization algorithms and also want to try with few other features like regions and country of origin.\n",
    "\n",
    "Hope you guys enjoyed the code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
